{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive learning of patterns via RNN\n",
    "\n",
    "After we have learned to predict the next note via a neural network, it still lacks the capability to\n",
    "\n",
    "* understand and predict \n",
    "* has no sense of time\n",
    "* is not aware of velocity/amplitude of a note\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch\n",
    "from ki_ueben.datasets import Maestro3Dataset\n",
    "from ki_ueben.midi import PianoRoll\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset = Maestro3Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': PosixPath('/Users/scheiba/github/ki-ueben-klavier-trainieren/book/chapters/data/maestro-v3.0.0/maestro-v3.0.0/2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--1.midi')}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_record = dataset[10]\n",
    "dataset_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the events within a MIDI file through the `PianoRoll` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PianoRoll(/Users/scheiba/github/ki-ueben-klavier-trainieren/book/chapters/data/maestro-v3.0.0/maestro-v3.0.0/2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--1.midi)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piano_roll = PianoRoll(dataset_record[\"file_path\"])\n",
    "piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>velocity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>0.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>0.997396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1.087240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>1.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>-1</td>\n",
       "      <td>69</td>\n",
       "      <td>389.126302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>-1</td>\n",
       "      <td>64</td>\n",
       "      <td>389.145833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>-1</td>\n",
       "      <td>55</td>\n",
       "      <td>389.164062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7304</th>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "      <td>389.184896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>389.204427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7306 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      note  velocity        time\n",
       "0       -1         0    0.000000\n",
       "1       51        49    0.980469\n",
       "2       63        57    0.997396\n",
       "3       51         0    1.087240\n",
       "4       50        64    1.093750\n",
       "...    ...       ...         ...\n",
       "7301    -1        69  389.126302\n",
       "7302    -1        64  389.145833\n",
       "7303    -1        55  389.164062\n",
       "7304    -1        37  389.184896\n",
       "7305    -1         0  389.204427\n",
       "\n",
       "[7306 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events = piano_roll.events()\n",
    "df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MidiVectorTransform:\n",
    "    \"\"\"Transforms multiple MIDI events stored within a DataFrame,\n",
    "    happening at the same time into a vector.\n",
    "    The DataFrame needs to have the columns\n",
    "\n",
    "    * velocity\n",
    "    * note\n",
    "    * time_delta (delta from previous event) - it is not necessary to quantize this\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, velocity_steps: int = 32, time_steps: int = 125, dtype=np.uint8):\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.velocity_steps = velocity_steps\n",
    "        self.velocity_mask = np.eye(self.velocity_steps, dtype=self.dtype)\n",
    "\n",
    "        self.time_steps = time_steps\n",
    "        self.time_mask = np.eye(self.time_steps, dtype=self.dtype)\n",
    "\n",
    "        self.num_midi = 128\n",
    "        self.midi_mask = np.eye(self.num_midi, dtype=self.dtype)\n",
    "\n",
    "    @property\n",
    "    def transform_size(self) -> int:\n",
    "        return (2 * self.num_midi) + self.velocity_steps + self.time_steps\n",
    "\n",
    "    def _events(self, df: pd.DataFrame, selector: Callable[[int], bool]) -> np.ndarray:\n",
    "        events = np.zeros(self.num_midi, dtype=self.dtype)\n",
    "        for _, event in df[df[\"velocity\"].apply(selector)].iterrows():\n",
    "            events = events + self.midi_mask[int(event.note)]\n",
    "        return events\n",
    "\n",
    "    def _events_on(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        return self._events(df, selector=lambda x: x > 0)\n",
    "\n",
    "    def _events_off(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        return self._events(df, selector=lambda x: x == 0)\n",
    "\n",
    "    def _velocity(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        # todo: should this ignore 0 velocity at all?\n",
    "        velocity = np.zeros(self.velocity_steps, dtype=self.dtype)\n",
    "\n",
    "        mean_velocity = df[df[\"velocity\"] > 0].velocity.mean()\n",
    "        if not pd.isna(mean_velocity):\n",
    "            quantized_velocity = int(\n",
    "                np.floor(mean_velocity / 127 * self.velocity_steps)\n",
    "            )\n",
    "            velocity = self.velocity_mask[quantized_velocity]\n",
    "\n",
    "        return velocity\n",
    "\n",
    "    def _time(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        time = np.zeros(self.time_steps, dtype=self.dtype)\n",
    "        if len(df) > 0:\n",
    "            # clip between 0 and 1\n",
    "            time_diff = np.clip(df.iloc[0].time_delta, 0.0, 1.0)\n",
    "            time = self.time_mask[\n",
    "                int(\n",
    "                    np.clip(\n",
    "                        np.floor(time_diff * self.time_steps), 0, self.time_steps - 1\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        return time\n",
    "\n",
    "    def un_transform(self, sample):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __call__(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        # filter out empty messages and pedal messages\n",
    "        df = df[df[\"note\"] != -1]\n",
    "        return np.concatenate(\n",
    "            [\n",
    "                self._events_on(df),\n",
    "                self._events_off(df),\n",
    "                self._velocity(df),\n",
    "                self._time(df),\n",
    "            ],\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "\n",
    "\n",
    "transformer = MidiVectorTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>velocity</th>\n",
       "      <th>time</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>quantized_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>0.997396</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1.087240</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>1.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>0.071615</td>\n",
       "      <td>1.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>-1</td>\n",
       "      <td>69</td>\n",
       "      <td>389.126302</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>389.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>-1</td>\n",
       "      <td>64</td>\n",
       "      <td>389.145833</td>\n",
       "      <td>0.018229</td>\n",
       "      <td>389.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>-1</td>\n",
       "      <td>55</td>\n",
       "      <td>389.164062</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>389.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7304</th>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "      <td>389.184896</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>389.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>389.204427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>389.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7306 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      note  velocity        time  time_delta  quantized_time\n",
       "0       -1         0    0.000000    0.980469           0.000\n",
       "1       51        49    0.980469    0.016927           0.976\n",
       "2       63        57    0.997396    0.089844           0.992\n",
       "3       51         0    1.087240    0.006510           1.080\n",
       "4       50        64    1.093750    0.071615           1.088\n",
       "...    ...       ...         ...         ...             ...\n",
       "7301    -1        69  389.126302    0.019531         389.120\n",
       "7302    -1        64  389.145833    0.018229         389.144\n",
       "7303    -1        55  389.164062    0.020833         389.160\n",
       "7304    -1        37  389.184896    0.019531         389.184\n",
       "7305    -1         0  389.204427    1.000000         389.200\n",
       "\n",
       "[7306 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def prepare_df(df: pd.DataFrame, num_time_steps: int = 125) -> pd.DataFrame:\n",
    "    df[\"time_delta\"] = df[\"time\"].diff(-1).abs().fillna(1.0)\n",
    "    df[\"quantized_time\"] = np.floor(df[\"time\"] * num_time_steps) / num_time_steps\n",
    "\n",
    "    # remove pedal\n",
    "    df = df[df[\"note\"] > 0]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_quantized_iterator(df: pd.DataFrame):\n",
    "    for group_df in df.groupby(\"quantized_time\"):\n",
    "        yield group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1276 [00:07<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "vectors: Dict[str, np.array] = {}\n",
    "\n",
    "for midi_path in tqdm(dataset):\n",
    "    vector = []\n",
    "\n",
    "    piano_roll = PianoRoll(dataset_record[\"file_path\"])\n",
    "    df = piano_roll.events()\n",
    "\n",
    "    for _, x in df_quantized_iterator(prepare_df(df)):\n",
    "        vector.append(transformer(x))\n",
    "\n",
    "    vectors[midi_path[\"file_path\"].name] = np.array(vector)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vectors[\"ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--1.midi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3667, 413)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PianoRoll(/Users/scheiba/github/ki-ueben-klavier-trainieren/book/chapters/data/maestro-v3.0.0/maestro-v3.0.0/2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--1.midi)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 413)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector[-1:, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(413, 512, num_layers=3, batch_first=True, dropout=0.3)\n",
      "  (linear): Linear(in_features=512, out_features=413, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LSTM(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int = 512,\n",
    "        midi_size: int = 128,\n",
    "        velocity_steps: int = 32,\n",
    "        time_steps: int = 125,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.velocity_steps = velocity_steps\n",
    "        self.time_steps = time_steps\n",
    "        self.midi_size = midi_size\n",
    "\n",
    "        self.input_dim = (2 * self.midi_size) + self.velocity_steps + self.time_steps\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=3,\n",
    "            dropout=0.3,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=self.hidden_size,\n",
    "            out_features=self.input_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # !!! batch needs to be!!!\n",
    "        # * midi_in\n",
    "        # * midi_out\n",
    "        # * velocity\n",
    "        # * time\n",
    "\n",
    "        lstm_out, (hn, cn) = self.lstm(batch)\n",
    "        # only select the last output of the lstm\n",
    "        # we need to unsqueeze because selecting a single element\n",
    "        # will delete the dimension as well\n",
    "        lstm_out = lstm_out[:, -1:, :]\n",
    "        return self.linear(lstm_out)\n",
    "\n",
    "    def note_on(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t[:, :, 0 : self.midi_size]\n",
    "\n",
    "    def note_off(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t[:, :, self.midi_size : self.midi_size * 2]\n",
    "\n",
    "    def velocity(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t[:, :, self.midi_size * 2 : (self.midi_size * 2) + self.velocity_steps]\n",
    "\n",
    "    def time(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        # @todo this is wrong!\n",
    "        return t[:, :, -self.time_steps :]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "\n",
    "        # losses = torch.concatenate([\n",
    "        #     nn.functional.mse_loss(self.note_on(y), self.note_on(out)),\n",
    "        #     # nn.CrossEntropyLoss()(self.velocity(x), self.velocity(out))\n",
    "        # ])\n",
    "\n",
    "        note_on_loss = nn.functional.mse_loss(self.note_on(out), self.note_on(y))\n",
    "        # have different losses for each section\n",
    "        time_loss = nn.functional.cross_entropy(self.time(out), self.time(y))\n",
    "\n",
    "        self.log(\"train_note_on_loss\", note_on_loss)\n",
    "        self.log(\"train_time_loss\", time_loss)\n",
    "\n",
    "        return note_on_loss + time_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "lstm = LSTM()\n",
    "\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.note_on(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, vectors: np.ndarray, num_pre: int, num_post: int = 1):\n",
    "        self.vectors = vectors\n",
    "        self.num_pre = num_pre\n",
    "        self.num_post = num_post\n",
    "\n",
    "    def __iter__(self) -> Iterator:\n",
    "        for offset in np.arange(\n",
    "            0, self.vectors.shape[0] + self.num_post + self.num_pre\n",
    "        ):\n",
    "            yield self.vectors[offset : offset + self.num_pre], self.vectors[\n",
    "                offset + self.num_pre : offset + self.num_pre + self.num_post\n",
    "            ]\n",
    "\n",
    "\n",
    "dataset = TimeSeriesDataset(\n",
    "    vectors=torch.Tensor(vector.astype(np.float32)), num_pre=100, num_post=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type   | Params\n",
      "----------------------------------\n",
      "0 | lstm   | LSTM   | 6.1 M \n",
      "1 | linear | Linear | 211 K \n",
      "----------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.251    Total estimated model params size (MB)\n",
      "/Users/scheiba/github/ki-ueben-klavier-trainieren/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:47<00:00,  2.10it/s, v_num=42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:47<00:00,  2.09it/s, v_num=42]\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(limit_train_batches=100, max_epochs=2, log_every_n_steps=1)\n",
    "trainer.fit(model=lstm, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_note_on_loss': tensor(0.0041), 'train_time_loss': tensor(-0.)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = lstm.forward(torch.Tensor(vector[0:100].astype(np.float32)).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.8971e-03, -1.2172e-03, -2.4754e-03, -3.7213e-03, -2.7787e-03,\n",
       "        -2.5138e-04,  1.7865e-03, -2.6892e-04,  1.8892e-03, -1.5990e-03,\n",
       "         3.2224e-04,  9.8781e-04, -1.4894e-03, -2.0432e-03,  2.9413e-03,\n",
       "        -1.7089e-03,  9.7648e-03, -1.2814e-03, -1.8693e-03, -3.8153e-03,\n",
       "        -5.2325e-03,  2.3664e-03,  8.2530e-04, -1.2044e-03, -2.1420e-03,\n",
       "        -6.7895e-04, -1.5671e-03,  2.7583e-03,  3.3898e-03,  5.4249e-03,\n",
       "        -2.0362e-03,  3.2021e-03, -9.8711e-04,  2.5240e-03, -2.1509e-04,\n",
       "        -1.2053e-04,  1.2406e-03,  3.5846e-04, -2.5151e-04, -5.0175e-03,\n",
       "        -2.1750e-03, -5.8116e-03,  8.4303e-03,  1.2473e-02,  3.3065e-03,\n",
       "         4.9784e-04,  3.2720e-03, -1.1198e-03,  5.0466e-03,  9.6616e-03,\n",
       "         6.7661e-03,  3.2104e-02,  1.1356e-02,  1.5208e-02,  2.1413e-02,\n",
       "        -1.3461e-03,  1.1828e-02, -4.4166e-03,  3.0715e-02,  1.0709e-02,\n",
       "         2.2356e-02,  1.2477e-02,  1.4657e-02,  4.9933e-02,  9.8639e-03,\n",
       "         5.0932e-03,  3.4576e-02,  2.8624e-02,  3.1148e-02,  1.4244e-02,\n",
       "         1.3624e-02,  9.0485e-03, -7.5996e-03,  2.4900e-02,  1.4314e-03,\n",
       "         2.4914e-02,  6.8576e-03,  1.8449e-02,  2.5721e-02, -2.2751e-03,\n",
       "         5.0112e-03, -1.4032e-03, -6.6324e-04, -5.5712e-05, -2.2678e-04,\n",
       "        -2.1236e-03,  6.7008e-03,  1.7317e-03,  7.5102e-06, -4.2326e-03,\n",
       "        -1.4865e-03, -1.9564e-03, -1.8173e-03, -7.5530e-03, -2.5971e-03,\n",
       "        -6.6896e-04, -2.8853e-04, -1.3860e-03, -2.9145e-03,  2.5233e-03,\n",
       "        -3.0141e-03, -1.8416e-03, -2.0920e-04,  1.3955e-03,  1.4082e-03,\n",
       "        -5.2320e-03, -2.2829e-04, -2.7252e-03, -1.8598e-03, -2.0533e-03,\n",
       "        -1.7556e-03, -1.3605e-03,  4.8952e-03, -6.1192e-03, -7.1883e-04,\n",
       "        -1.2520e-03, -1.8946e-03, -3.9329e-03, -3.3910e-03,  2.0080e-03,\n",
       "         1.1569e-04, -7.0281e-04, -5.2682e-03, -2.6927e-03, -1.9303e-03,\n",
       "        -2.0103e-03,  1.6549e-03,  2.7641e-03,  2.3737e-02,  1.2776e-02,\n",
       "        -2.2792e-02, -3.7656e-02,  1.2028e-02,  2.9068e-02, -2.7538e-02,\n",
       "        -3.8140e-02,  2.2985e-02, -2.0768e-02, -3.9148e-02,  3.3403e-02,\n",
       "         3.2566e-02,  3.4457e-02,  2.2134e-02,  7.2785e-03,  4.5199e-02,\n",
       "         1.7560e-02,  7.3990e-03,  3.3805e-02, -3.9054e-03, -1.8722e-02,\n",
       "        -1.9900e-02,  4.3101e-02, -4.0593e-02, -1.9847e-02,  2.0040e-02,\n",
       "        -3.5919e-02, -2.3761e-02,  5.2724e-03,  4.3978e-02,  2.7625e-02,\n",
       "        -3.8861e-02,  3.1229e-02,  3.2987e-02,  2.5322e-02, -2.1601e-02,\n",
       "        -3.3452e-02, -3.9446e-02, -4.9163e-02,  2.5905e-02,  7.3373e-03,\n",
       "         4.4806e-03,  2.7141e-02,  1.0308e-02, -1.1387e-02, -3.5696e-02,\n",
       "        -4.5360e-02,  8.0430e-03, -3.9659e-02, -3.9769e-02, -4.3226e-02,\n",
       "         1.8576e-02, -7.3207e-03,  1.6507e-02, -2.1918e-03,  3.0971e-02,\n",
       "        -4.7017e-03, -3.3365e-02,  2.5517e-03, -6.6097e-03,  4.1712e-02,\n",
       "        -3.1158e-02, -2.7735e-02, -4.5749e-02, -2.0409e-02,  6.6859e-03,\n",
       "        -3.3338e-02, -1.7701e-02, -2.5616e-03,  5.9042e-03, -1.5096e-02,\n",
       "         2.7269e-02, -1.3449e-02,  1.9918e-02,  1.4246e-02, -2.9368e-02,\n",
       "         3.9403e-03, -3.1972e-02,  3.8182e-02, -8.6633e-03,  2.3459e-02,\n",
       "        -2.0701e-02,  3.2765e-02, -6.4843e-03,  3.5714e-02, -6.7283e-03,\n",
       "        -3.3848e-02,  4.5694e-02,  3.9664e-02,  3.8251e-02,  4.2845e-02,\n",
       "         5.9987e-03, -1.6130e-02,  4.6555e-02,  4.5439e-02,  2.0768e-02,\n",
       "         3.1304e-02,  2.8316e-02,  2.3103e-02,  2.5092e-02, -4.9728e-02,\n",
       "        -2.1685e-02,  3.3223e-02,  2.2863e-03,  4.0384e-02,  3.2432e-02,\n",
       "         6.8279e-03,  3.4870e-02, -1.8543e-02,  2.4752e-02, -2.0220e-02,\n",
       "        -1.8563e-02, -3.8347e-03,  2.4133e-02,  7.9473e-03,  4.3926e-02,\n",
       "         4.4744e-02,  1.6670e-03, -1.0041e-02,  4.6717e-02,  4.3535e-03,\n",
       "        -3.7917e-03, -4.2693e-02, -3.8575e-02,  3.9670e-02, -3.0533e-02,\n",
       "         1.4539e-02, -2.7041e-02, -1.3461e-02,  3.4271e-02,  2.6884e-02,\n",
       "         3.3698e-02, -2.1815e-02, -3.6171e-02,  3.7228e-02, -2.3271e-02,\n",
       "         1.6165e-02, -1.9304e-02, -1.0806e-02,  2.4865e-02,  2.8080e-02,\n",
       "        -3.3596e-02,  1.5015e-02,  1.9676e-02,  9.4632e-03,  2.6891e-02,\n",
       "        -2.8566e-02,  1.3460e-02,  4.5108e-02,  4.1301e-02, -4.6732e-02,\n",
       "         2.1529e-02, -5.0594e-03, -2.3084e-02,  4.9358e-03,  4.7264e-02,\n",
       "        -3.4201e-02,  4.4690e-02,  1.9649e-02,  2.4159e-02, -4.1604e-02,\n",
       "        -2.9940e-02, -1.6085e-02, -2.1004e-02, -1.6435e-02, -1.0687e-02,\n",
       "        -3.8009e-02,  3.4674e-02, -3.9884e-02, -1.3196e-02, -4.0335e-02,\n",
       "         4.6765e-02,  9.6048e-03,  2.8515e-02,  4.8117e-02, -2.4999e-02,\n",
       "        -1.2368e-02,  1.7255e-02,  2.0706e-02,  2.2120e-02,  7.2939e-03,\n",
       "        -1.8978e-02, -1.8084e-02, -1.7331e-02,  1.0563e-02, -1.2415e-02,\n",
       "         9.9599e-03, -3.6635e-02,  1.6644e-02, -4.1848e-02,  1.6299e-03,\n",
       "        -3.6215e-02,  3.0513e-02,  1.3567e-02,  3.8604e-02,  4.3125e-02,\n",
       "        -4.0514e-02,  2.7093e-02,  2.8078e-02, -1.2638e-02,  1.9425e-02,\n",
       "         4.5069e-02, -3.8987e-02,  3.9404e-02, -2.5092e-02,  1.0052e-03,\n",
       "        -4.1483e-02,  4.0935e-03,  3.2575e-02,  1.0139e-02,  3.7838e-02,\n",
       "        -3.6300e-02, -4.6253e-02, -2.3956e-02, -2.2817e-02, -1.9818e-02,\n",
       "        -3.7306e-02, -1.4942e-02, -2.6097e-02,  3.0904e-02, -1.2205e-02,\n",
       "         1.7287e-02, -3.5403e-02, -2.7734e-02,  1.8749e-02, -4.7736e-02,\n",
       "        -4.1799e-02, -3.2422e-02, -1.5975e-03,  3.0155e-02, -3.3387e-02,\n",
       "        -1.1106e-03,  2.5647e-02, -1.3699e-02, -1.1126e-02,  2.5204e-02,\n",
       "        -3.0537e-02, -2.1189e-02,  1.7125e-02,  3.0578e-02, -2.4332e-02,\n",
       "        -1.8495e-02,  7.4440e-03,  4.2622e-02, -2.2923e-02, -3.8553e-02,\n",
       "        -4.8918e-04, -3.5645e-02,  2.3841e-02, -3.9050e-03,  1.8616e-02,\n",
       "        -3.8206e-02, -4.0831e-02, -2.4276e-02, -2.5626e-03, -6.6222e-03,\n",
       "         4.1509e-02, -4.2947e-02, -1.6525e-02,  4.6827e-02, -1.3096e-02,\n",
       "         1.5053e-03,  2.4252e-02, -1.3178e-02,  2.2984e-02, -2.5244e-02,\n",
       "        -2.0906e-03, -2.5289e-02,  2.8134e-02,  1.8045e-02,  4.0391e-02,\n",
       "        -3.0290e-02, -2.2061e-02, -3.6481e-02, -3.9591e-02, -4.5669e-02,\n",
       "         1.9075e-02, -1.7979e-02, -4.6694e-02, -3.8227e-02, -4.4380e-02,\n",
       "        -9.1604e-03,  4.2172e-02,  1.0153e-04], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(lstm.velocity(out)[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.note_on(out)[0, 0] > 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.velocity_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0518, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.velocity(out[0, 0]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(lstm.time(out[0, 0]).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 413])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out > 0.2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6677, 413)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(vectors[:-1]), torch.Tensor(vectors[1:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([413])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[10][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = lstm.forward(\n",
    "    torch.Tensor(vectors[10:20]).unsqueeze(dim=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 413)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[10:20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 333])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(L.LightningModule):\n",
    "    def __init__(\n",
    "        self, mp \n",
    "        n_features=88,\n",
    "        hidden_size=12,\n",
    "        seq_len=12,\n",
    "        batch_size=12,\n",
    "        num_layers=12,\n",
    "        dropout=0.2,\n",
    "        output_size=88,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_features = n_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.output_size = output_size\n",
    "    \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.n_features,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=self.dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
