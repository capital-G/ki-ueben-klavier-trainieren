{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation of sonic data\n",
    "\n",
    "Musical information can be stored in a variety of ways and also evolved through history.\n",
    "One big transition was for example the capability to store the waveform of a place and time through a physical object, which then again can be re-processed and transformed back into a pressure wave of air through loudspeakers.\n",
    "\n",
    "Another common method is the notation of notes through a score, and while this inscription covers a large domain of western music history it also lacks fundamental aspects of precise information, opening the room for interpretation.\n",
    "\n",
    "The idea of transcribing the action of practicing a piano into a score reveals that such a score struggles representing common topics in practicing such as\n",
    "\n",
    "* flucuation in tempo\n",
    "* small deviations in timing\n",
    "* precise articulation of a note\n",
    "\n",
    "The score fails to represent this data because it favors a more idealistic proposition of a performance than to represent an actual, definitive version.\n",
    "\n",
    "The deviation between score and performance is the very essence of an interpretation of a piece.\n",
    "Training the piano covers therefore not only the physical capability of hitting keys at the right time but also their pronunciation which is hinted by the score but relies on a more direct connection to the music in order to transport the musical intention and idea of a musical idea.\n",
    "\n",
    "A common way to represent the performance on a keyboard is through [MIDI](https://en.wikipedia.org/wiki/MIDI), which allows to store the the pressing and releasing of each key at specific time points with a given pressure which is represented via $2^{7} = 128$ steps.\n",
    "\n",
    "While within a digital domain the representation is faithful, attaching it to physical objects may introduce *smearing* as the transition between the physical action to a digital quantized information may introduce a delta.\n",
    "\n",
    "While the representation of MIDI is also limited, it also provides a sweet spot of a reasonable approximation of a given performance and has the advantage of being a standard which allows interaction with many different kind of instruments and software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing MIDI files\n",
    "\n",
    "Python has a variety of MIDI libraries and this course decides to go with [`pretty_midi`](https://github.com/craffel/pretty-midi) which provides some nice convenience methods.\n",
    "\n",
    "In order to obtain a basic understanding of MIDI data it is a good practice to parse a simple MIDI file, for example [31 Good Night To You All.mid](https://commons.wikimedia.org/wiki/File:31_Good_Night_To_You_All.mid) from Wikimedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x04\\x03\\xc0MTrk\\x00\\x00\\x00)\\x00\\xffX\\x04\\x03\\x02\\x18\\x08\\x00\\xffY\\x02\\xff\\x00\\x00\\xffQ\\x03\\t'\\xc0\\x00\\xff\\x02\\x0cCopyright \\xa9 \\x01\\xff/\\x00MTrk\\x00\\x00\\x02.\\x8f\\x00\\xc0\\x00\\x00\\xb0y\\x00\\x00\\xb0@\\x00\\x00\\xb0[0\\x00\\xb0\\n3\\x00\\xb0\\x07d\\x00\\xff\\x03\\x05P\"\n"
     ]
    }
   ],
   "source": [
    "midi_file_path = \"../data/31_Good_Night_To_You_All.mid\"\n",
    "\n",
    "with open(midi_file_path, \"rb\") as f:\n",
    "    midi_data = f.read()\n",
    "\n",
    "print(midi_data[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply using the data from a MIDI file is not helpful as the data is binary encoded.\n",
    "The library `pretty_midi` allows to turn this binary data into Python objects, allowing the extraction and interaction with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "\n",
    "midi_file = pretty_midi.PrettyMIDI(midi_file=midi_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIDI files are not limited to represent one instrument but can instead encapsule a multitude of instruments simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instrument(program=0, is_drum=False, name=\"Piano\"),\n",
       " Instrument(program=0, is_drum=False, name=\"Piano\"),\n",
       " Instrument(program=0, is_drum=False, name=\"Piano\")]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_file.instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each instrument contains a series of events, which covers data such as when a note is pressed (`note_on`) and when a a note is released (`note_off`).\n",
    "Each note event contains the information\n",
    "\n",
    "* pitch\n",
    "* time\n",
    "* velocity\n",
    "\n",
    "`pretty_midi` combines the pair of `note_on` and `note_off` to a single event which makes it more convenient to work with MIDI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Note(start=1.200000, end=1.800000, pitch=72, velocity=76),\n",
       " Note(start=1.800000, end=2.400000, pitch=74, velocity=77),\n",
       " Note(start=2.400000, end=3.000000, pitch=72, velocity=75),\n",
       " Note(start=3.000000, end=3.600000, pitch=70, velocity=74),\n",
       " Note(start=3.600000, end=4.800000, pitch=69, velocity=74),\n",
       " Note(start=4.800000, end=5.400000, pitch=69, velocity=76),\n",
       " Note(start=5.400000, end=6.000000, pitch=67, velocity=75),\n",
       " Note(start=6.000000, end=6.600000, pitch=65, velocity=74),\n",
       " Note(start=6.600000, end=7.200000, pitch=64, velocity=74),\n",
       " Note(start=7.200000, end=8.400000, pitch=65, velocity=76)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_file.instruments[0].notes[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although MIDI can store information such as tempo and time signature, it is not mandatory.\n",
    "For this project, these information is not important as practicing is not tied to a consistent tempo.\n",
    "\n",
    "Where traditional sheet music is derived from a visual representation, MIDI is not relying on a visual representation and instead tries to capture a stream of events of a keyboard on a timeline.\n",
    "Yet a common method to represent MIDI data in a visual way is the piano roll, which is derived from the traditional piano roll of player pianos.\n",
    "\n",
    "The $x$ axis represents the progression through time, while the $y$ axis represents the possible keys on a piano (which there are 88 of on a traditional grand piano).\n",
    "If a key $k$ is is pressed down at a time point $T$, the point $(t, k)$ is mapped to 1, and if no key is pressed down, it is mapped to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1101ccee0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "piano_roll = midi_file.get_piano_roll()[21 : 21 + 88]\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(piano_roll[:, 0:1000], interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "midi_folder = Path(\"../data/pianoteq/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 772 midi files\n"
     ]
    }
   ],
   "source": [
    "midi_file_paths: List[Path] = []\n",
    "\n",
    "for root, dir, files in os.walk(midi_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mid\"):\n",
    "            midi_path = Path(root).joinpath(\"/\".join(dir), file)\n",
    "            midi_file_paths.append(midi_path)\n",
    "\n",
    "print(f\"Found {len(midi_file_paths)} midi files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano_rolls = []\n",
    "\n",
    "for midi_file_path in midi_file_paths:\n",
    "    m = pretty_midi.PrettyMIDI(midi_file=str(midi_file_path.absolute()))\n",
    "    piano_rolls.append(m.get_piano_roll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piano_roll = piano_rolls[0]\n",
    "piano_roll[:, ::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class PianoRollDataset(Dataset):\n",
    "    def __init__(self, piano_rolls: List[np.ndarray], sample_length: int = 1000):\n",
    "        # @todo allow padding and more arbitrary cuts\n",
    "        # @todo skip empty samples\n",
    "        # @todo allow for reduction in piano key range\n",
    "        super().__init__()\n",
    "        self.piano_rolls = piano_rolls\n",
    "        self.sample_length = sample_length\n",
    "        self._prepare_dataset()\n",
    "\n",
    "    def _prepare_dataset(self):\n",
    "        self.data: List[np.ndarray] = []\n",
    "        for piano_roll in self.piano_rolls:\n",
    "            for offset in range(0, piano_roll.shape[1], self.sample_length):\n",
    "                sample = piano_roll[:, offset : offset + self.sample_length].astype(\n",
    "                    np.float32\n",
    "                )\n",
    "                if sample.shape[-1] == self.sample_length:\n",
    "                    self.data.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17062"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piano_rolls_dataset = PianoRollDataset(\n",
    "    piano_rolls=piano_rolls,\n",
    ")\n",
    "len(piano_rolls_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 90620)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piano_rolls[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=128000, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=128000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # hardcoded - needs to be dynamic according to the input data\n",
    "            nn.Linear(128 * 1000, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 128 * 1000),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(self.flatten(x))\n",
    "        return torch.reshape(logits, shape=(-1, 128, 1000))\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = SimpleNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: torch.Size([64, 128, 1000])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "dataloader = DataLoader(piano_rolls_dataset, batch_size=batch_size)\n",
    "\n",
    "for X in dataloader:\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, X in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, X)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4577.022461  [   64/17062]\n",
      "loss: 1506.752075  [ 6464/17062]\n",
      "loss: 1539.838501  [12864/17062]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2218.559082  [   64/17062]\n",
      "loss: 1506.428467  [ 6464/17062]\n",
      "loss: 1539.534546  [12864/17062]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2218.207275  [   64/17062]\n",
      "loss: 1506.105103  [ 6464/17062]\n",
      "loss: 1539.230591  [12864/17062]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2217.855957  [   64/17062]\n",
      "loss: 1505.782227  [ 6464/17062]\n",
      "loss: 1538.927002  [12864/17062]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2217.504883  [   64/17062]\n",
      "loss: 1505.459717  [ 6464/17062]\n",
      "loss: 1538.624023  [12864/17062]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader, model, loss_fn, optimizer)\n",
    "    # test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
