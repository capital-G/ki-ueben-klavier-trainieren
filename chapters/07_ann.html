
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7. Artificial Neural networks &#8212; KI üben, Klavier trainieren</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css?v=4c607a41" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/07_ann';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8. Recurrent learning of patterns via RNN" href="08_rnn.html" />
    <link rel="prev" title="6. Representation of Sonic Data" href="06_representation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">KI üben, Klavier trainieren</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    KI üben, Klavier trainieren
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction &amp; Overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../preface.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup.html">Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_training.html">1. Training and Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_artificial.html">2. The artificial</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_what-to-learn.html">3. What can be learned?</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_measuring.html">4. Measuring</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_markov.html">5. The likelihood of the successive note</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_representation.html">6. Representation of Sonic Data</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">7. Artificial Neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_rnn.html">8. Recurrent learning of patterns via RNN</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendices/player_limitations.html">Player Piano limitations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/player_piano_evening.html">Player Piano Evening</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/ki_ueben_api.html">ki_ueben API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/glossary.html">Glossary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-gitlab"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://gitlab.com/robert-schumann-hochschule/imm/ki-ueben-klavier-trainieren" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-gitlab"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://gitlab.com/robert-schumann-hochschule/imm/ki-ueben-klavier-trainieren/-/edit/main/book/chapters/07_ann.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/07_ann.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Artificial Neural networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-seasons-of-ai">7.1. The seasons of AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-program-a-neural-network">7.2. How to program a neural network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fully-connected-neural-networks">7.3. Fully connected neural networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-and-iteration">7.4. Implementation and iteration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-fcnn">7.4.1. Simple FCNN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predicting-probabilities">7.4.2. Predicting probabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-context">7.4.3. Adding context</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="artificial-neural-networks">
<h1><span class="section-number">7. </span>Artificial Neural networks<a class="headerlink" href="#artificial-neural-networks" title="Link to this heading">#</a></h1>
<section id="the-seasons-of-ai">
<h2><span class="section-number">7.1. </span>The seasons of AI<a class="headerlink" href="#the-seasons-of-ai" title="Link to this heading">#</a></h2>
<p>The development of AI have always been met with hype cycles.
As seen with the McCulloch Pitts model, many foundations of “<em>AI</em>” have already been laid out in the 1940/1950s, but these constructs failed to meet their high expectations and promises, which finally lead to an abandonment of <em>AI</em> research, a circumstance labeled as an <a class="reference external" href="https://en.wikipedia.org/wiki/AI_winter">AI Winter</a>.</p>
<p>In the early 1980s, new architectures in neural networks and training methods re-initiated an interest in neural networks, but the the promised advancements were not met and by the 1990s other machine learning methods such as <a class="reference external" href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machine (SVM)</a> were the focus of attention, which offered more reliable results in a more comprehensive theoretical framework, therefore the AI research went out of focus in the 90s.</p>
<p>The exact starting point of the current hype wave of AI or artifical neural networks is hard to pin down, but one crucial development were the results of <a class="reference external" href="https://en.wikipedia.org/wiki/AlexNet"><em>AlexNet</em></a> in 2012, which managed to get an increase in accuracy by 10% over the next entry, a rare circumstance which gets lots of attention.
One thing that AlexNet taken advantage of was to use <a class="reference external" href="https://en.wikipedia.org/wiki/Kernel_(image_processing)"><em>convolutions</em></a> as a learnable part of a neural network architecture.
This architecture is inspired by the biological structure of the neurons within the visual cortex and was already proposed in the 1980s as <a class="reference external" href="https://en.wikipedia.org/wiki/Neocognitron"><em>Neocognitron</em></a>.
But only due to the wide and cheap availability of GPUs through the gaming industry (which helped to reduce the time for the training procedure from months to days), as well as the availability of big datasets through the capturing measures of big data companies (which allowed to train a neural network with billions of parameters on a dataset of millions of pictures instead of thousands) allowed to re-visit the proposed architecture from the 1980s with big success.</p>
<p>The question of the current season of AI is therefore always apparent and unclear and is caused as well as a reason of the unpredictable nature of AIs topologies, which allows to enter the realm of dreams and desires of companies which try to construct new opportunities of profits, therefore the dreams of companies have to be realized by <em>“AI”</em>, and a failing of this does not result in a disadvantage for the dreamer but for the dream itself.</p>
<p><em>AI</em> is therefore not a recent or new field of research, but had a coming and going which has been attached to the availability or lack of breakthroughs.</p>
</section>
<section id="how-to-program-a-neural-network">
<h2><span class="section-number">7.2. </span>How to program a neural network<a class="headerlink" href="#how-to-program-a-neural-network" title="Link to this heading">#</a></h2>
<p>While traditional programming uses algorithms to describe the output for a given input, programming neural networks involves more setting up an environment or topology with many degrees of freedom (<em>“variables”</em>) and a <em>traning</em> process, in which these degrees of freedom are tuned to a set of <em>samples</em> which traditionally contain a <em>sample</em> of the input data and an associated desired output.</p>
<p>There are lots of variations of how this topology or this training process can be constructed, and new paths in the structuring of these</p>
<p>This setup still requires the use a combination of different crucial algorithms such as <a class="reference external" href="https://en.wikipedia.org/wiki/Automatic_differentiation">AutoDiff</a> (an algorithm for automatic partial differentiation) or optimizing algorithms such as <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam">Adam</a>.
Instead of implementing those algorithms oneself, it is possible to use libraries which implement a variety of these algorithms and also have optimized versions for GPU available and there is a variety of libraries available these days.</p>
<p>This course will use <a class="reference external" href="https://lightning.ai/docs/pytorch/stable/"><em>PyTorch Lightning</em></a> which implement common default and is build on top of <a class="reference external" href="https://pytorch.org/"><em>PyTorch</em></a>, which provides a Python interface to all the necessary algorithms for the following chapters.</p>
</section>
<section id="fully-connected-neural-networks">
<h2><span class="section-number">7.3. </span>Fully connected neural networks<a class="headerlink" href="#fully-connected-neural-networks" title="Link to this heading">#</a></h2>
<p>A <em>fully connected neural network</em> is one of the basic architectures of neural networks.
It works by having multiple <em>layers</em> which each consist of multiple <em>neurons</em>.
Each neuron of a layer is connected to every neuron of its successive layer, therefore it is called a <em>fully connected</em> layer or neural network.
Each connection is modeled as a multiplication of the value with a <em>weight</em> of the connection.
All incoming connections of a neuron are then summed together, resulting in a new value which either acts as the output or act as intermediate value used as input for another layer (in which case the layer is called a hidden layer).</p>
<figure class="align-center" id="id1">
<img alt="An artifical neural network with 3 fully connected layers" src="https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg" />
<figcaption>
<p><span class="caption-number">Fig. 7.1 </span><span class="caption-text">An artifical neural network with an input layer which consists of 3 input neurons, a hidden layer consisting of 4 neurons and an output layer with two neurons.
As all every neuron is <em>connected</em> with every neuron in the subsequent layer, this is called a <em>fully connected</em> network.
Note that the connections are also directed, so there is no way to introduce feedback loops - something which biological networks tend to form.
Source: <a class="reference external" href="https://en.wikipedia.org/wiki/File:Colored_neural_network.svg">https://en.wikipedia.org/wiki/File:Colored_neural_network.svg</a></span><a class="headerlink" href="#id1" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="implementation-and-iteration">
<h2><span class="section-number">7.4. </span>Implementation and iteration<a class="headerlink" href="#implementation-and-iteration" title="Link to this heading">#</a></h2>
<section id="simple-fcnn">
<h3><span class="section-number">7.4.1. </span>Simple FCNN<a class="headerlink" href="#simple-fcnn" title="Link to this heading">#</a></h3>
<p>As a first introduction to neural networks, we will formulate, train, and evaluate a fully connected neural network that simply predicts the next note given the current note.
This is somehow similar to the previous discussed Perceptron and Markov chain discussed earlier.</p>
<p>Our goal is to predict the next note given a sequence of notes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">lightning</span> <span class="k">as</span> <span class="nn">L</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="k">class</span> <span class="nc">SimpleFCNN</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="c1"># 1 input neuron -&gt; hidden layer w/ 4 neurons</span>
            <span class="c1"># we add a bias neuron to account for offsets</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="c1"># relu layer as activation</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="c1"># hidden layer w/ 4 neurons -&gt; 1 output neuron</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># scalar value needs to be wrapped into a an</span>
        <span class="c1"># additional dimension</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># z is the predicted note</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">test_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test_loss&quot;</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">test_loss</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>


<span class="n">simple_fcnn</span> <span class="o">=</span> <span class="n">SimpleFCNN</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">simple_fcnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SimpleFCNN(
  (net): Sequential(
    (0): Linear(in_features=1, out_features=4, bias=True)
    (1): ReLU()
    (2): Linear(in_features=4, out_features=1, bias=True)
  )
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.model_summary</span> <span class="kn">import</span> <span class="n">ModelSummary</span>

<span class="n">ModelSummary</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">simple_fcnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  | Name | Type       | Params | Mode 
--------------------------------------------
0 | net  | Sequential | 13     | train
--------------------------------------------
13        Trainable params
0         Non-trainable params
13        Total params
0.000     Total estimated model params size (MB)
4         Modules in train mode
0         Modules in eval mode
</pre></div>
</div>
</div>
</div>
<p>The summary above tells us that we have 13 parameters.</p>
<div class="math notranslate nohighlight">
\[
\underbrace{((1+\underbrace{1}_{\text{bias}})*4)}_{\text{input -&gt; hidden}} + \underbrace{((4+\underbrace{1}_{\text{bias}})*1)}_{\text{hidden -&gt; output}} = 13
\]</div>
<p>There is also the question on how to evaluate the performance?
In the <code class="docutils literal notranslate"><span class="pre">training_step</span></code> method we refer to a <em>mse_loss</em> which stands for <a class="reference external" href="https://en.wikipedia.org/wiki/Mean_squared_error"><em>mean squared error</em></a>, which is simply the average error squared (it is squared so a negative and positive error do not cancel out each other but do indeed accumulate), so</p>
<div class="math notranslate nohighlight">
\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} \left( Y_i - \hat{Y_i}\ \right) ^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(Y\)</span> being the actual value and <span class="math notranslate nohighlight">\(\hat{Y}\)</span> the predicted value.</p>
<p>Now it is time to actually load the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">ki_ueben.datasets</span> <span class="kn">import</span> <span class="n">Maestro3Dataset</span>
<span class="kn">from</span> <span class="nn">ki_ueben.midi</span> <span class="kn">import</span> <span class="n">PianoRoll</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">note_dfs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">maestro_files</span> <span class="o">=</span> <span class="n">Maestro3Dataset</span><span class="p">()</span>

<span class="c1"># limit files - set to -1 for no limits</span>
<span class="n">NUM_FILES</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># limit to first 100</span>
<span class="k">for</span> <span class="n">midi_path</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">maestro_files</span><span class="p">[:</span><span class="n">NUM_FILES</span><span class="p">][</span><span class="s2">&quot;file_path&quot;</span><span class="p">]):</span>
    <span class="n">piano_roll</span> <span class="o">=</span> <span class="n">PianoRoll</span><span class="p">(</span><span class="n">midi_path</span><span class="p">)</span>
    <span class="n">df_events</span> <span class="o">=</span> <span class="n">piano_roll</span><span class="o">.</span><span class="n">events</span><span class="p">()</span>
    <span class="c1"># filter out pedal (note=-1) and note_off events (velocity=0)</span>
    <span class="n">df_events</span> <span class="o">=</span> <span class="n">df_events</span><span class="p">[(</span><span class="n">df_events</span><span class="p">[</span><span class="s2">&quot;note&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_events</span><span class="p">[</span><span class="s2">&quot;velocity&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span>
    <span class="n">df_events</span><span class="p">[</span><span class="s2">&quot;note&quot;</span><span class="p">]</span>
    <span class="n">note_dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df_events</span><span class="p">)</span>

<span class="n">simple_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">note_dfs</span><span class="p">)</span>
<span class="n">simple_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 100/100 [00:39&lt;00:00,  2.50it/s]
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>note</th>
      <th>velocity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>77</td>
      <td>56</td>
      <td>0.994792</td>
    </tr>
    <tr>
      <th>2</th>
      <td>49</td>
      <td>32</td>
      <td>0.998698</td>
    </tr>
    <tr>
      <th>4</th>
      <td>73</td>
      <td>58</td>
      <td>1.108073</td>
    </tr>
    <tr>
      <th>6</th>
      <td>68</td>
      <td>58</td>
      <td>1.207031</td>
    </tr>
    <tr>
      <th>8</th>
      <td>73</td>
      <td>62</td>
      <td>1.315104</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4811</th>
      <td>69</td>
      <td>60</td>
      <td>216.302083</td>
    </tr>
    <tr>
      <th>4812</th>
      <td>78</td>
      <td>70</td>
      <td>216.867188</td>
    </tr>
    <tr>
      <th>4816</th>
      <td>79</td>
      <td>68</td>
      <td>217.937500</td>
    </tr>
    <tr>
      <th>4818</th>
      <td>71</td>
      <td>57</td>
      <td>217.954427</td>
    </tr>
    <tr>
      <th>4819</th>
      <td>74</td>
      <td>54</td>
      <td>217.957031</td>
    </tr>
  </tbody>
</table>
<p>458219 rows × 3 columns</p>
</div></div></div>
</div>
<p>As we want to predict the <em>next</em> note, we need to create a pair of the given sequence (<span class="math notranslate nohighlight">\(X\)</span>) and the target value (<span class="math notranslate nohighlight">\(y\)</span>).
This can by simply shifting the data indices by 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data.dataset</span> <span class="kn">import</span> <span class="n">TensorDataset</span>

<span class="c1"># offset the data by 1 between X and y</span>
<span class="n">simple_data_X</span> <span class="o">=</span> <span class="n">simple_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;note&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">simple_data_y</span> <span class="o">=</span> <span class="n">simple_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:][</span><span class="s2">&quot;note&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">simple_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span>
    <span class="c1"># convert midi note (int) to float as neural networks require floating</span>
    <span class="c1"># point numbers to calculate gradients, not discrete integers</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">simple_data_X</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">simple_data_y</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_train_items</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">simple_dataset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">num_test_items</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">simple_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">num_train_items</span>

<span class="c1"># split the dataset</span>
<span class="n">simple_train</span><span class="p">,</span> <span class="n">simple_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">simple_dataset</span><span class="p">,</span>
    <span class="n">lengths</span><span class="o">=</span><span class="p">[</span><span class="n">num_train_items</span><span class="p">,</span> <span class="n">num_test_items</span><span class="p">],</span>
    <span class="c1"># manual seeding so split is deterministic</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To actually feed a stream of data into a neural network we use a <a class="reference external" href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"><code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a>.
This is necessary as we most likely can’t fit all data at once through our neural network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">simple_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">persistent_workers</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">simple_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we are set and we can start the actual training process.
We will limit our training to 5 <em>epochs</em> - we will</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_lightning.loggers</span> <span class="kn">import</span> <span class="n">CSVLogger</span>

<span class="n">simple_trainer</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">logger</span><span class="o">=</span><span class="p">[</span>
        <span class="c1"># we store the metrics into a CSV file so we can take a look at its progress later</span>
        <span class="n">CSVLogger</span><span class="p">(</span><span class="n">save_dir</span><span class="o">=</span><span class="s2">&quot;logs&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;simple_fcnn&quot;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">],</span>
<span class="p">)</span>
<span class="n">simple_trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">simple_fcnn</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/Users/scheiba/github/ki-ueben-klavier-trainieren/venv/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory logs/simple_fcnn/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
/Users/scheiba/github/ki-ueben-klavier-trainieren/venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory logs/simple_fcnn/version_0/checkpoints exists and is not empty.

  | Name | Type       | Params | Mode 
--------------------------------------------
0 | net  | Sequential | 13     | train
--------------------------------------------
13        Trainable params
0         Non-trainable params
13        Total params
0.000     Total estimated model params size (MB)
4         Modules in train mode
0         Modules in eval mode
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 0:   1%|          | 25/2864 [00:00&lt;01:16, 37.03it/s, v_num=0, train_loss=8.28e+3]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/v0/7q67mljd4v9_frk_1p_mr2ph0000gn/T/ipykernel_11183/2857180159.py:37: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss = nn.functional.mse_loss(y_hat, y)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1:   1%|          | 20/2864 [00:00&lt;00:26, 106.37it/s, v_num=0, train_loss=385.0]   
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/v0/7q67mljd4v9_frk_1p_mr2ph0000gn/T/ipykernel_11183/2857180159.py:37: UserWarning: Using a target size (torch.Size([110])) that is different to the input size (torch.Size([110, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss = nn.functional.mse_loss(y_hat, y)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: 100%|██████████| 2864/2864 [00:21&lt;00:00, 134.30it/s, v_num=0, train_loss=258.0]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`Trainer.fit` stopped: `max_epochs=5` reached.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: 100%|██████████| 2864/2864 [00:21&lt;00:00, 134.26it/s, v_num=0, train_loss=258.0]
</pre></div>
</div>
</div>
</div>
<p>The training of even such a very simple network takes some time, but hopefully we will see that the loss will lower over time.
To read the CSV data into Python we will use pandas again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;svg&#39;

<span class="n">df_simple_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;logs/simple_fcnn/version_0/metrics.csv&quot;</span><span class="p">)</span>
<span class="n">df_simple_metrics</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">line</span><span class="p">(</span>
    <span class="n">grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Simple FCNN loss&quot;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/3be38253ccfd38b06bf32c1d9a21d3caa7c08ceefbe5cf96ac043f983730c13d.svg" src="../_images/3be38253ccfd38b06bf32c1d9a21d3caa7c08ceefbe5cf96ac043f983730c13d.svg" />
</div>
</div>
<p>We can now evaluate the model on our test data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simple_trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">simple_fcnn</span><span class="p">,</span> <span class="n">dataloaders</span><span class="o">=</span><span class="n">test_loader</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/scheiba/github/ki-ueben-klavier-trainieren/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The &#39;test_dataloader&#39; does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Testing DataLoader 0: 100%|██████████| 179/179 [00:01&lt;00:00, 119.90it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        test_loss            176.2259521484375
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
</div>
</div>
<p>Like previously in our mark chain, we can now iterate over the net by guessing the next note.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">latest_note</span> <span class="o">=</span> <span class="mi">38</span>

<span class="n">notes</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">notes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">latest_note</span><span class="p">)</span>
    <span class="n">latest_note</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">simple_fcnn</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">latest_note</span><span class="p">)]))[</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">notes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[38, 54, 60, 62, 62, 62, 62, 62, 62, 62]
</pre></div>
</div>
</div>
</div>
</section>
<section id="predicting-probabilities">
<h3><span class="section-number">7.4.2. </span>Predicting probabilities<a class="headerlink" href="#predicting-probabilities" title="Link to this heading">#</a></h3>
<p>So training neural networks is not too hard, but the network is not too complex yet.</p>
<p>One problem at the moment, however, is that it will always output the same <em>road</em> for a given starting note, because the network has been trained to output a value based on an input.</p>
<p>To make our output more flexible, we want to output, similar to the Markov chain, a probability distribution for the next note, given the current note.</p>
<p>To get this work we will need to adapt the in- and output dimensions of the neural network as it now needs to predict the probability for each possible successive note.
We also need to transform our dataset as it needs now to be <a class="reference external" href="https://en.wikipedia.org/wiki/One-hot">one-hot vectors</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ProbabilityFCNN</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="c1"># 1 input neuron -&gt; hidden layer w/ 4 neurons</span>
            <span class="c1"># we add a bias neuron to account for offsets</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">88</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="c1"># relu layer as activation</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="c1"># hidden layer w/ 4 neurons -&gt; 1 output neuron</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">88</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>


<span class="n">probability_fcnn</span> <span class="o">=</span> <span class="n">ProbabilityFCNN</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">probability_fcnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ProbabilityFCNN(
  (net): Sequential(
    (0): Linear(in_features=88, out_features=24, bias=True)
    (1): ReLU()
    (2): Linear(in_features=24, out_features=88, bias=True)
  )
  (criterion): CrossEntropyLoss()
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ModelSummary</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">probability_fcnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  | Name      | Type             | Params | Mode 
-------------------------------------------------------
0 | net       | Sequential       | 4.3 K  | train
1 | criterion | CrossEntropyLoss | 0      | train
-------------------------------------------------------
4.3 K     Trainable params
0         Non-trainable params
4.3 K     Total params
0.017     Total estimated model params size (MB)
5         Modules in train mode
0         Modules in eval mode
</pre></div>
</div>
</div>
</div>
<p>That is already a lot more parameters - sit down for one moment and try to understand why there are now so much more parameters by calculating the number of parameters manually.</p>
<p>We will continue by transforming our dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># -21 to scale data down to 0</span>
<span class="n">one_hot_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">88</span><span class="p">)[</span><span class="n">simple_df</span><span class="p">[</span><span class="s2">&quot;note&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="mi">21</span><span class="p">]</span>

<span class="c1"># offset the data by 1 between X and y</span>
<span class="n">probability_data_X</span> <span class="o">=</span> <span class="n">one_hot_data</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">probability_data_y</span> <span class="o">=</span> <span class="n">one_hot_data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="n">probability_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span>
    <span class="c1"># convert midi note (int) to float as neural networks require floating</span>
    <span class="c1"># point numbers to calculate gradients, not discrete integers</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">probability_data_X</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">probability_data_y</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># one sample vector</span>
<span class="n">one_hot_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">probability_train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">probability_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">persistent_workers</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">probability_trainer</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">logger</span><span class="o">=</span><span class="p">[</span>
        <span class="c1"># we store the metrics into a CSV file so we can take a look at its progress later</span>
        <span class="n">CSVLogger</span><span class="p">(</span><span class="n">save_dir</span><span class="o">=</span><span class="s2">&quot;logs&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;probability_fcnn&quot;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">],</span>
<span class="p">)</span>

<span class="n">probability_trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">probability_fcnn</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">probability_train_loader</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/Users/scheiba/github/ki-ueben-klavier-trainieren/venv/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory logs/probability_fcnn/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
/Users/scheiba/github/ki-ueben-klavier-trainieren/venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory logs/probability_fcnn/version_0/checkpoints exists and is not empty.

  | Name      | Type             | Params | Mode 
-------------------------------------------------------
0 | net       | Sequential       | 4.3 K  | train
1 | criterion | CrossEntropyLoss | 0      | train
-------------------------------------------------------
4.3 K     Trainable params
0         Non-trainable params
4.3 K     Total params
0.017     Total estimated model params size (MB)
5         Modules in train mode
0         Modules in eval mode
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: 100%|██████████| 3580/3580 [00:30&lt;00:00, 117.22it/s, v_num=0, train_loss=3.660]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`Trainer.fit` stopped: `max_epochs=5` reached.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: 100%|██████████| 3580/3580 [00:30&lt;00:00, 117.19it/s, v_num=0, train_loss=3.660]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_prob_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;logs/probability_fcnn/version_0/metrics.csv&quot;</span><span class="p">)</span>
<span class="n">df_prob_metrics</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">line</span><span class="p">(</span>
    <span class="n">grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Prob FCNN loss&quot;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e8954f1a28b54bf4092f39c251ff43582cc2ed278db01a222f55663a00aea9cf.svg" src="../_images/e8954f1a28b54bf4092f39c251ff43582cc2ed278db01a222f55663a00aea9cf.svg" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">START_NOTE</span> <span class="o">=</span> <span class="mi">60</span>

<span class="n">start_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">88</span><span class="p">)[</span><span class="n">START_NOTE</span> <span class="o">-</span> <span class="mi">21</span><span class="p">]</span>

<span class="n">logits_vector</span> <span class="o">=</span> <span class="n">probability_fcnn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">start_vector</span><span class="p">))</span>
<span class="n">prob_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits_vector</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">prob_vector</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([5.3904032e-06, 9.7931224e-06, 6.5958493e-06, 1.1832035e-04,
       2.0422945e-05, 7.9910802e-05, 2.0841567e-04, 2.4010161e-04,
       2.8074645e-03, 3.2075937e-04, 8.9785451e-04, 1.3693562e-03,
       1.7685634e-03, 5.4534886e-04, 1.3101222e-03, 1.1381200e-02,
       1.0323367e-03, 3.5103934e-03, 3.4037919e-03, 4.4841897e-03,
       7.0898021e-03, 2.4060169e-03, 9.7995587e-03, 3.7993125e-03,
       8.2788365e-03, 6.7118732e-03, 4.8370576e-03, 6.3701861e-02,
       4.1270871e-03, 1.3559097e-02, 1.3995913e-02, 1.0293804e-02,
       2.6983807e-02, 7.9926075e-03, 4.3171227e-02, 1.5701288e-02,
       5.1756598e-02, 2.3058120e-02, 1.7784920e-02, 1.9332737e-02,
       7.0023746e-03, 3.7463475e-02, 6.4986460e-02, 3.7811551e-02,
       4.0689424e-02, 1.5034327e-02, 4.5700327e-02, 1.7222449e-02,
       3.2818682e-02, 1.6703313e-02, 1.2920220e-02, 6.1218675e-02,
       4.2455150e-03, 1.8142229e-02, 2.6042564e-02, 1.2941089e-02,
       1.8677060e-02, 4.6163960e-03, 2.7335418e-02, 9.3086008e-03,
       1.6528221e-02, 7.7258451e-03, 5.0773569e-03, 2.0772977e-02,
       2.7441760e-03, 5.1642167e-03, 4.9710879e-03, 7.4942741e-03,
       6.3071973e-03, 2.1137653e-03, 7.4743587e-03, 1.8489923e-03,
       2.5457256e-03, 2.1587887e-03, 1.4705472e-03, 3.4613395e-03,
       2.8797289e-04, 7.9179934e-04, 7.4524642e-04, 6.9696095e-04,
       6.1217818e-04, 7.7609555e-05, 7.9020203e-05, 2.9790672e-05,
       3.8298407e-05, 2.0419321e-07, 9.4376702e-08, 2.2757520e-08],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Probabilites for the next note, starting from </span><span class="si">{</span><span class="n">START_NOTE</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">88</span><span class="p">)</span> <span class="o">+</span> <span class="mi">21</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">prob_vector</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/056b3ebb79feb5c0e4a0dfa70e2eff2a36b90173ca6a6f4a544021c9a4604db0.svg" src="../_images/056b3ebb79feb5c0e4a0dfa70e2eff2a36b90173ca6a6f4a544021c9a4604db0.svg" />
</div>
</div>
<p>We can now turn this into a series again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">prob_vector</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">p</span><span class="o">=</span><span class="n">prob_vector</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>29
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">START_NOTE</span> <span class="o">=</span> <span class="mi">60</span>

<span class="n">start_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">88</span><span class="p">)[</span><span class="n">START_NOTE</span> <span class="o">-</span> <span class="mi">21</span><span class="p">]</span>
<span class="n">notes</span> <span class="o">=</span> <span class="p">[</span><span class="n">START_NOTE</span><span class="p">]</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>
    <span class="n">logits_vector</span> <span class="o">=</span> <span class="n">probability_fcnn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">start_vector</span><span class="p">))</span>
    <span class="n">prob_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits_vector</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">next_note</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">prob_vector</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">p</span><span class="o">=</span><span class="n">prob_vector</span><span class="p">)</span>
    <span class="n">notes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_note</span><span class="p">)</span>
    <span class="n">start_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">prob_vector</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">next_note</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
    <span class="p">)</span>

<span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">note</span><span class="p">)</span> <span class="k">for</span> <span class="n">note</span> <span class="ow">in</span> <span class="n">notes</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;60, 39, 66, 63, 67, 44, 27, 39, 26, 34, 55, 46, 48, 50, 58, 58, 54, 49, 43, 24, 12, 19, 36, 46, 58, 39, 43, 56, 45, 48, 39, 44, 53, 51, 48, 49, 11, 9, 23, 40, 52&#39;
</pre></div>
</div>
</div>
</div>
<p>We already are not stuck anymore on a single note!</p>
</section>
<section id="adding-context">
<h3><span class="section-number">7.4.3. </span>Adding context<a class="headerlink" href="#adding-context" title="Link to this heading">#</a></h3>
<p>Although the model already improved, we can still improve it by providing some context through a series of notes as input, e.g. the latest 5.</p>
<p>As we currently don’t want to go into details about multi-dimensional input data with means such as convolution, we will simply concatenate the 5 vectors into one long vector as input and will output only 1 vector.
The network should figure out the importance of each input-dimension by itself.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CONTEXT_NUM_NOTES</span> <span class="o">=</span> <span class="mi">5</span>


<span class="k">class</span> <span class="nc">ContextFCNN</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_notes</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_notes</span> <span class="o">*</span> <span class="mi">88</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">88</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="c1"># turn 5x88 matrix into 440 dim vector</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>


<span class="n">context_fcnn</span> <span class="o">=</span> <span class="n">ContextFCNN</span><span class="p">(</span><span class="n">num_notes</span><span class="o">=</span><span class="n">CONTEXT_NUM_NOTES</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">context_fcnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ContextFCNN(
  (net): Sequential(
    (0): Linear(in_features=440, out_features=24, bias=True)
    (1): ReLU()
    (2): Linear(in_features=24, out_features=88, bias=True)
  )
  (criterion): CrossEntropyLoss()
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ModelSummary</span><span class="p">(</span><span class="n">context_fcnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  | Name      | Type             | Params | Mode 
-------------------------------------------------------
0 | net       | Sequential       | 12.8 K | train
1 | criterion | CrossEntropyLoss | 0      | train
-------------------------------------------------------
12.8 K    Trainable params
0         Non-trainable params
12.8 K    Total params
0.051     Total estimated model params size (MB)
5         Modules in train mode
0         Modules in eval mode
</pre></div>
</div>
</div>
</div>
<p>Again, we also need to adjust our data transformation workflow.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># -21 to scale data down to 0</span>
<span class="n">one_hot_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">88</span><span class="p">)[</span><span class="n">simple_df</span><span class="p">[</span><span class="s2">&quot;note&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="mi">21</span><span class="p">]</span>

<span class="c1"># offset the data by 1 between X and y</span>
<span class="n">probability_data_X</span> <span class="o">=</span> <span class="n">one_hot_data</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">probability_data_y</span> <span class="o">=</span> <span class="n">one_hot_data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="c1"># one sample vector</span>
<span class="n">one_hot_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">context_X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">context_y</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># not efficient, but works</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">one_hot_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">CONTEXT_NUM_NOTES</span><span class="p">):</span>
    <span class="n">context_X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">one_hot_data</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">CONTEXT_NUM_NOTES</span><span class="p">])</span>
    <span class="n">context_y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">one_hot_data</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">CONTEXT_NUM_NOTES</span><span class="p">])</span>

<span class="n">context_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">context_X</span><span class="p">)</span>
<span class="n">context_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">context_y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;context_X: </span><span class="si">{</span><span class="n">context_X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, context_y: </span><span class="si">{</span><span class="n">context_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>context_X: (458214, 5, 88), context_y: (458214, 88)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">context_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span>
    <span class="c1"># convert midi note (int) to float as neural networks require floating</span>
    <span class="c1"># point numbers to calculate gradients, not discrete integers</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">context_X</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">context_y</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">context_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">context_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">persistent_workers</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">context_trainer</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">logger</span><span class="o">=</span><span class="p">[</span>
        <span class="c1"># we store the metrics into a CSV file so we can take a look at its progress later</span>
        <span class="n">CSVLogger</span><span class="p">(</span><span class="n">save_dir</span><span class="o">=</span><span class="s2">&quot;logs&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;context_fcnn&quot;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">],</span>
<span class="p">)</span>

<span class="n">context_trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">context_fcnn</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">context_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/Users/scheiba/github/ki-ueben-klavier-trainieren/venv/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory logs/context_fcnn/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
/Users/scheiba/github/ki-ueben-klavier-trainieren/venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory logs/context_fcnn/version_0/checkpoints exists and is not empty.

  | Name      | Type             | Params | Mode 
-------------------------------------------------------
0 | net       | Sequential       | 12.8 K | train
1 | criterion | CrossEntropyLoss | 0      | train
-------------------------------------------------------
12.8 K    Trainable params
0         Non-trainable params
12.8 K    Total params
0.051     Total estimated model params size (MB)
5         Modules in train mode
0         Modules in eval mode
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: 100%|██████████| 7160/7160 [01:03&lt;00:00, 112.03it/s, v_num=0, train_loss=3.020]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`Trainer.fit` stopped: `max_epochs=5` reached.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: 100%|██████████| 7160/7160 [01:03&lt;00:00, 112.01it/s, v_num=0, train_loss=3.020]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_prob_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;logs/context_fcnn/version_0/metrics.csv&quot;</span><span class="p">)</span>
<span class="n">df_prob_metrics</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">line</span><span class="p">(</span>
    <span class="n">grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Context FCNN loss&quot;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2a7e39fc7c5ed7cddf59ac31ffa4d6826b3c74cfef292fa6e6103e88a2cd6335.svg" src="../_images/2a7e39fc7c5ed7cddf59ac31ffa4d6826b3c74cfef292fa6e6103e88a2cd6335.svg" />
</div>
</div>
<p>The training loss does not look very good - it is hard to say what the problem here is.
We can still use the method form before to continue a sequence.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">START_SEQUENCE</span> <span class="o">=</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">58</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span> <span class="mi">55</span><span class="p">]</span>

<span class="n">start_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">88</span><span class="p">)[</span><span class="n">START_SEQUENCE</span><span class="p">]</span>
<span class="n">notes</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="n">START_SEQUENCE</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>
    <span class="n">logits_vector</span> <span class="o">=</span> <span class="n">context_fcnn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">start_vector</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">prob_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits_vector</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">next_note</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">prob_vector</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">p</span><span class="o">=</span><span class="n">prob_vector</span><span class="p">)</span>
    <span class="n">notes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_note</span><span class="p">)</span>
    <span class="n">start_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">88</span><span class="p">)[</span><span class="n">notes</span><span class="p">[(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="p">:</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
    <span class="p">)</span>

<span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">note</span><span class="p">)</span> <span class="k">for</span> <span class="n">note</span> <span class="ow">in</span> <span class="n">notes</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;60, 58, 60, 53, 55, 43, 57, 58, 53, 55, 58, 46, 58, 58, 52, 53, 56, 51, 46, 31, 53, 47, 43, 39, 46, 24, 34, 34, 45, 41, 50, 34, 33, 34, 43, 34, 31, 34, 27, 43, 29, 46, 29, 48, 46&#39;
</pre></div>
</div>
</div>
</div>
<p>Although fully-connected artificial networks already gave us some insights into machine learning we will stop here.
One problem that we are facing currently is that the size of our context needs to be of fixed size - this means our network will grow more and more if we want more context, which is problematic because it takes longer to train and also takes more data to train a bigger network.</p>
<p>Instead we will take a look into <em>recurrent neural networks</em> (RNN), which implement a feedback loop which we can use to create a context of arbitrary size.</p>
<div class="admonition-task admonition">
<p class="admonition-title">Task</p>
<ul class="simple">
<li><p>Try to add time and/or velocity into the neural network by extending its in- and output structure</p></li>
<li><p>Instead of the MSE (mean squared error), we now use a <em>cross entropy loss</em> - why?</p></li>
<li><p>What is the softmax function and why do we apply it on the output of our network?</p></li>
<li><p>Use OSC to create a communication bridge between SuperCollider and Python - try to control a melody in SuperCollider via the neural network. Take a look at <a class="reference external" href="https://github.com/attwad/python-osc"><code class="docutils literal notranslate"><span class="pre">python-osc</span></code></a></p></li>
</ul>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="06_representation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">6. </span>Representation of Sonic Data</p>
      </div>
    </a>
    <a class="right-next"
       href="08_rnn.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8. </span>Recurrent learning of patterns via RNN</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-seasons-of-ai">7.1. The seasons of AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-program-a-neural-network">7.2. How to program a neural network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fully-connected-neural-networks">7.3. Fully connected neural networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-and-iteration">7.4. Implementation and iteration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-fcnn">7.4.1. Simple FCNN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predicting-probabilities">7.4.2. Predicting probabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-context">7.4.3. Adding context</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dennis Scheiba, Institut für Musik und Medien, Robert Schumann Hochschule Düsseldorf
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023, 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>